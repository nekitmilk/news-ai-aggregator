import json
import redis
import pika
import logging
import threading
from queue import Queue
from manager import SummarizerManager

logger = logging.getLogger("NewsConsumer")
logger.setLevel(logging.INFO)
ch = logging.StreamHandler()
formatter = logging.Formatter("[%(asctime)s] [%(levelname)s] %(message)s")
ch.setFormatter(formatter)
logger.addHandler(ch)


class NewsConsumer:
    def __init__(self, conf: dict):
        self.conf = conf

        self.redis_client = redis.StrictRedis(
            host=conf['redis']['host'],
            port=conf['redis']['port'],
            db=conf['redis'].get('db', 0),
            decode_responses=True
        )
        logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis —É—Å–ø–µ—à–Ω–æ")

        self.rabbit_connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=conf['rabbitmq']['host'],
                port=conf['rabbitmq'].get('port', 5672),
                credentials=pika.PlainCredentials(
                    conf['rabbitmq']['user'],
                    conf['rabbitmq']['password']
                ),
                heartbeat=600,  # 10 –º–∏–Ω—É—Ç
                blocked_connection_timeout=300
            )
        )
        self.channel = self.rabbit_connection.channel()
        self.channel.queue_declare(queue=conf['rabbitmq']['queue'], durable=True)
        self.channel.basic_qos(prefetch_count=1)
        logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ —É—Å–ø–µ—à–Ω–æ")

        logger.info("‚è≥ –ó–∞–≥—Ä—É–∂–∞–µ–º Summarizer –Ω–∞ GPU...")
        self.summarizer_manager = SummarizerManager(device=0)
        logger.info("‚úÖ Summarizer –∑–∞–≥—Ä—É–∂–µ–Ω")

        self.model_queue = Queue()
        self.model_thread = threading.Thread(target=self.model_worker, daemon=True)
        self.model_thread.start()

        self.channel.basic_consume(
            queue=conf['rabbitmq']['queue'],
            on_message_callback=self.callback,
            auto_ack=False
        )

    def model_worker(self):
        """–û—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é"""
        while True:
            key, text, ch, method = self.model_queue.get()
            try:
                summary, duration = self.summarizer_manager.summarize(text)
                logger.info(f"[SUMMARY]: {summary}")
                logger.info(f"‚è± –í—Ä–µ–º—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {duration:.2f} —Å–µ–∫")

                ch.basic_ack(delivery_tag=method.delivery_tag)

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}", exc_info=True)
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

            finally:
                self.model_queue.task_done()

    def start_consuming(self):
        logger.info("üöÄ –ö–æ–Ω—Å—é–º–µ—Ä –∑–∞–ø—É—â–µ–Ω. –û–∂–∏–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        try:
            self.channel.start_consuming()
        except KeyboardInterrupt:
            logger.info("üõë –ö–æ–Ω—Å—é–º–µ—Ä –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É.")
        except pika.exceptions.StreamLostError as e:
            logger.warning(f"‚ö†Ô∏è –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å RabbitMQ –ø–æ—Ç–µ—Ä—è–Ω–æ: {e}, –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è...")
            self.__init__(self.conf)
            self.start_consuming()

    def callback(self, ch, method, properties, body):
        key = body.decode('utf-8')
        logger.info(f"üì© –ü–æ–ª—É—á–µ–Ω –∫–ª—é—á –∏–∑ RabbitMQ: {key}")

        news_json = self.redis_client.get(key)
        if not news_json:
            logger.warning(f"‚ö†Ô∏è –ö–ª—é—á '{key}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Redis")
            ch.basic_ack(delivery_tag=method.delivery_tag)
            return

        news_data = json.loads(news_json)
        header = news_data.get('header')
        text = news_data.get('text', "")

        logger.info(f"üì∞ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {header}")
        logger.info(f"üìÖ –î–∞—Ç–∞: {news_data.get('date')}")
        logger.info(f"üîó URL: {news_data.get('url')}")

        if text.strip():
            try:
                summary, duration = self.summarizer_manager.summarize(text)
                logger.info(f"[SUMMARY]: {summary}")
                logger.info(f"‚è± –í—Ä–µ–º—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {duration:.2f} —Å–µ–∫")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}", exc_info=True)
            finally:
                ch.basic_ack(delivery_tag=method.delivery_tag)
        else:
            logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø—É—Å—Ç–æ–π, —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞")
            ch.basic_ack(delivery_tag=method.delivery_tag)


if __name__ == "__main__":
    with open("config.json", 'r', encoding='utf-8') as file:
        conf = json.load(file)

    consumer = NewsConsumer(conf)
    consumer.start_consuming()
