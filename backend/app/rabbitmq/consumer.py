import json
import logging
import asyncio
from typing import Dict, Any
from urllib.parse import urlparse
import aio_pika
from aio_pika.abc import AbstractIncomingMessage
from sqlmodel import Session, select
from datetime import datetime

from app.core.config import settings
from app.core.db import engine
from app.models import ProcessedNews, Source, Category

logger = logging.getLogger(__name__)

class NewsConsumer:
    def __init__(self):
        self.connection = None
        self.channel = None
        self.is_connected = False
        self.reconnect_delay = settings.RABBITMQ_RECONNECT_DELAY  # seconds
        self.is_running = True
    
    async def connect(self):
        """–ü—Ä–æ—Å—Ç–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ"""
        try:
            self.connection = await aio_pika.connect_robust(
                settings.RABBITMQ_URL,
                timeout=10
            )
            self.channel = await self.connection.channel()
            await self.channel.set_qos(prefetch_count=10)
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –æ—á–µ—Ä–µ–¥–∏
            self.queue = await self.channel.get_queue(
                settings.RABBITMQ_PROCESSED_NEWS_QUEUE
            )
            
            if self.queue is None:
                raise ConnectionError(f"Queue {settings.RABBITMQ_PROCESSED_NEWS_QUEUE} not found")
            
            self.is_connected = True
            logger.info("‚úÖ Successfully connected to RabbitMQ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Connection failed: {e}")
            self.is_connected = False
            return False
    
    async def wait_for_connection(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        while self.is_running and not self.is_connected:
            logger.info(f"üîÑ Waiting for RabbitMQ... (retry in {self.reconnect_delay}s)")
            await asyncio.sleep(self.reconnect_delay)
            
            if await self.connect():
                return True
        
        return False
    
    async def start_consuming(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è —Å –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–º –æ–∂–∏–¥–∞–Ω–∏–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        while self.is_running:
            if not self.is_connected:
                # –ñ–¥–µ–º –ø–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è
                if not await self.wait_for_connection():
                    continue
            
            try:
                # –ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π
                await self.queue.consume(self.process_message)
                logger.info("üéØ Started consuming messages from RabbitMQ")
                
                # –ñ–¥–µ–º –ø–æ–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ
                await asyncio.Future()  # –ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ
                
            except asyncio.CancelledError:
                logger.info("Consumer was cancelled")
                break
            except Exception as e:
                logger.error(f"‚ùå Connection lost: {e}")
                self.is_connected = False
                await self.disconnect()
    
    async def process_message(self, message: AbstractIncomingMessage):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        try:
            async with message.process():
                news_data = json.loads(message.body.decode())
                logger.info(f"üì® Processing: {news_data.get('title')}")
                await self.save_processed_news(news_data)
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Invalid JSON: {e}")
        except Exception as e:
            logger.error(f"‚ùå Message processing error: {e}")
    
    async def save_processed_news(self, news_data: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –ë–î"""
        try:
            with Session(engine) as session:
                title = news_data.get("title", "").strip()

                published_date = news_data.get("published_date", "")
                if not published_date:
                    published_date = datetime.now()

                summary=news_data.get("summary", "").strip()
                
                if not title or not summary:
                    logger.error("Missing required fields")
                    return
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç –ø–æ URL
                existing = session.exec(
                    select(ProcessedNews).where(ProcessedNews.url == news_data.get("url", ""))
                ).first()
                if existing:
                    logger.info(f"‚ö†Ô∏è News already exists: {title}")
                    return
                
                source_name = news_data.get("source_name", "Unknown Source").strip()
                source_url = news_data.get("url", "").strip()
                source_domain = self.extract_domain(source_url)
                
                source = await self.get_or_create_source(session, source_name, source_domain)
                category = await self.get_or_create_category(session, news_data.get("category", "general").strip())
                
                db_news = ProcessedNews(
                    title=title,
                    summary=summary,
                    url=source_url,
                    published_at=published_date,
                    source_id=source.id,
                    category_id=category.id
                )
                
                session.add(db_news)
                session.commit()
                logger.info(f"‚úÖ Saved: {title}")
                
        except Exception as e:
            logger.error(f"‚ùå Save error: {e}")
    
    def extract_domain(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ URL"""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain if domain else "unknown-domain"
        except Exception:
            return "unknown-domain"
    
    async def get_or_create_source(self, session: Session, name: str, domain: str) -> Source:
        statement = select(Source).where(Source.name == name)
        source = session.exec(statement).first()
        if not source:
            source = Source(name=name, domain=domain)
            session.add(source)
            session.commit()
            session.refresh(source)
            logger.info(f"üìù Created source: {name}")
        return source
    
    async def get_or_create_category(self, session: Session, name: str) -> Category:
        statement = select(Category).where(Category.name == name)
        category = session.exec(statement).first()
        if not category:
            category = Category(name=name)
            session.add(category)
            session.commit()
            session.refresh(category)
            logger.info(f"üìù Created category: {name}")
        return category
    
    async def disconnect(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ"""
        if self.connection:
            await self.connection.close()
            self.is_connected = False
            logger.info("üîå Disconnected from RabbitMQ")
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è"""
        self.is_running = False
        await self.disconnect()
        logger.info("üõë Consumer stopped")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
news_consumer = NewsConsumer()